{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d04dd2-db53-42cf-9ffe-da28c6596cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcca6baa59f4251b493d50e504a4a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from skimage import io as skio, filters # Alias skimage.io to skio\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.spatial.distance import euclidean\n",
    "from skimage.exposure import equalize_hist\n",
    "import io # Explicitly import the standard Python io module\n",
    "\n",
    "\n",
    "class FingerprintMatcher:\n",
    "    def __init__(self):\n",
    "        # Create output widget for all messages\n",
    "        self.output_widget = widgets.Output()\n",
    "        display(self.output_widget)\n",
    "\n",
    "        # Initialize state\n",
    "        self.ref_image = None\n",
    "        self.samp_image = None\n",
    "\n",
    "        # Create upload widgets\n",
    "        self.ref_upload = widgets.FileUpload(\n",
    "            description='Reference Image',\n",
    "            accept='.jpg,.jpeg,.png,.bmp',\n",
    "            multiple=False\n",
    "        )\n",
    "        self.samp_upload = widgets.FileUpload(\n",
    "            description='Sample Image',\n",
    "            accept='.jpg,.jpeg,.png,.bmp',\n",
    "            multiple=False\n",
    "        )\n",
    "\n",
    "        # Create process and match buttons\n",
    "        self.process_btn = widgets.Button(description='Process Images')\n",
    "        self.match_btn = widgets.Button(description='Match Fingerprints')\n",
    "\n",
    "        # Connect button clicks to functions\n",
    "        self.process_btn.on_click(self._process_images)\n",
    "        self.match_btn.on_click(self._match_fingerprints)\n",
    "\n",
    "        # Display all widgets\n",
    "        with self.output_widget:\n",
    "            print(\"Fingerprint Matcher initialized\")\n",
    "            display(self.ref_upload)\n",
    "            display(self.samp_upload)\n",
    "            display(self.process_btn)\n",
    "            display(self.match_btn)\n",
    "\n",
    "    def _preprocess_image(self, image_path):\n",
    "        with self.output_widget:\n",
    "            print(f\"Processing image\")\n",
    "            try:\n",
    "                # Read image using PIL from bytes\n",
    "                img_bytes = image_path.tobytes()\n",
    "                img = Image.open(io.BytesIO(img_bytes)) # Use standard Python io.BytesIO\n",
    "\n",
    "                # Convert to grayscale if needed\n",
    "                if img.mode != 'L':\n",
    "                    img = img.convert('L')\n",
    "\n",
    "                # Convert to numpy array\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Apply histogram equalization\n",
    "                enhanced_img = equalize_hist(img_array)\n",
    "\n",
    "                return enhanced_img\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "\n",
    "    def _extract_features(self, processed_image):\n",
    "        with self.output_widget:\n",
    "            print(\"Extracting features...\")\n",
    "            try:\n",
    "                # Ridge detection using Sobel filters\n",
    "                sobel_x = filters.sobel_h(processed_image)\n",
    "                sobel_y = filters.sobel_v(processed_image)\n",
    "\n",
    "                # Combine gradients\n",
    "                gradient = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "                # Find local maxima for minutiae points\n",
    "                min_distance = 10\n",
    "                # threshold = 0.4 * gradient.max()  <- REMOVED\n",
    "                coordinates = peak_local_max(gradient, min_distance=min_distance,\n",
    "                                                    # threshold=threshold) <- REMOVED\n",
    "                                                    )\n",
    "\n",
    "                return coordinates\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting features: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "    def _match_features(self, ref_points, samp_points):\n",
    "        with self.output_widget:\n",
    "            print(\"Matching features...\")\n",
    "            try:\n",
    "                # Calculate distances between all point pairs\n",
    "                distances = []\n",
    "                for ref_point in ref_points:\n",
    "                    for samp_point in samp_points:\n",
    "                        dist = euclidean(ref_point, samp_point)\n",
    "                        distances.append(dist)\n",
    "\n",
    "                # Threshold for acceptable matches\n",
    "                threshold = 10\n",
    "                matches = sum(d < threshold for d in distances)\n",
    "\n",
    "                # Calculate similarity score\n",
    "                max_possible_matches = min(len(ref_points), len(samp_points))\n",
    "                similarity_score = (matches / max_possible_matches) * 100\n",
    "\n",
    "                return similarity_score\n",
    "            except Exception as e:\n",
    "                print(f\"Error during matching: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "    def _process_images(self, b):\n",
    "        with self.output_widget:\n",
    "            print(\"\\n=== Processing Images ===\")\n",
    "            # Get uploaded files\n",
    "            ref_files = self.ref_upload.value\n",
    "            samp_files = self.samp_upload.value\n",
    "\n",
    "            print(f\"Type of ref_files: {type(ref_files)}\")  # Debug print - Keep for now for verification\n",
    "            print(f\"Value of ref_files: {ref_files}\")    # Debug print - Keep for now for verification\n",
    "            print(f\"Type of samp_files: {type(samp_files)}\") # Debug print - Keep for now for verification\n",
    "            print(f\"Value of samp_files: {samp_files}\")   # Debug print - Keep for now for verification\n",
    "\n",
    "\n",
    "            if not ref_files or not samp_files:\n",
    "                print(\"Error: Please upload both reference and sample images\")\n",
    "                return\n",
    "\n",
    "            # Process reference image\n",
    "            if ref_files:\n",
    "                # Assume ref_files is a tuple of Bunch objects\n",
    "                for ref_file_info in ref_files: # Iterate directly over the tuple\n",
    "                    print(f\"Processing reference file: {ref_file_info}\") # Debug print - print the Bunch object\n",
    "                    self.ref_image = self._preprocess_image(ref_file_info['content']) # Access 'content'\n",
    "                    break  # Since multiple=False, process only the first file in the tuple\n",
    "\n",
    "            # Process sample image\n",
    "            if samp_files:\n",
    "                # Assume samp_files is a tuple of Bunch objects\n",
    "                for samp_file_info in samp_files: # Iterate directly over the tuple\n",
    "                    print(f\"Processing sample file: {samp_file_info}\") # Debug print - print the Bunch object\n",
    "                    self.samp_image = self._preprocess_image(samp_file_info['content']) # Access 'content'\n",
    "                    break  # Since multiple=False, process only the first file in the tuple\n",
    "\n",
    "\n",
    "            if self.ref_image is None or self.samp_image is None:\n",
    "                print(\"Error: Failed to process one or both images\")\n",
    "                return\n",
    "\n",
    "            # Display processed images\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            axes[0].imshow(self.ref_image, cmap='gray')\n",
    "            axes[0].set_title('Reference Image')\n",
    "            axes[1].imshow(self.samp_image, cmap='gray')\n",
    "            plt.show()\n",
    "            print(\"Images processed successfully!\")\n",
    "\n",
    "\n",
    "    def _match_fingerprints(self, b):\n",
    "        with self.output_widget:\n",
    "            print(\"\\n=== Matching Fingerprints ===\")\n",
    "            if self.ref_image is None or self.samp_image is None:\n",
    "                print(\"Error: Please process images first\")\n",
    "                return\n",
    "\n",
    "            # Extract features\n",
    "            ref_features = self._extract_features(self.ref_image)\n",
    "            samp_features = self._extract_features(self.samp_image)\n",
    "\n",
    "            if ref_features is None or samp_features is None:\n",
    "                print(\"Error: Failed to extract features\")\n",
    "                return\n",
    "\n",
    "            # Match features\n",
    "            score = self._match_features(ref_features, samp_features)\n",
    "\n",
    "            if score is not None:\n",
    "                print(f\"\\nMatching Results:\")\n",
    "                print(f\"Similarity Score: {score:.2f}%\")\n",
    "            else:\n",
    "                print(\"Error: Failed to calculate similarity score\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fingerprint_matcher = FingerprintMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c622b7a2-90fc-45db-a5cb-dd0865905dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d7ab58db22422cb3d87da1eb7d1fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from skimage import io as skio, filters # Alias skimage.io to skio\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.spatial.distance import euclidean\n",
    "from skimage.exposure import equalize_hist\n",
    "import io # Explicitly import the standard Python io module\n",
    "\n",
    "\n",
    "class FingerprintMatcher:\n",
    "    def __init__(self):\n",
    "        # Create output widget for all messages\n",
    "        self.output_widget = widgets.Output()\n",
    "        display(self.output_widget)\n",
    "\n",
    "        # Initialize state\n",
    "        self.ref_image = None\n",
    "        self.samp_image = None\n",
    "\n",
    "        # Create upload widgets\n",
    "        self.ref_upload = widgets.FileUpload(\n",
    "            description='Reference Image',\n",
    "            accept='.jpg,.jpeg,.png,.bmp',\n",
    "            multiple=False\n",
    "        )\n",
    "        self.samp_upload = widgets.FileUpload(\n",
    "            description='Sample Image',\n",
    "            accept='.jpg,.jpeg,.png,.bmp',\n",
    "            multiple=False\n",
    "        )\n",
    "\n",
    "        # Create process and match buttons\n",
    "        self.process_btn = widgets.Button(description='Process Images')\n",
    "        self.match_btn = widgets.Button(description='Match Fingerprints')\n",
    "\n",
    "        # Connect button clicks to functions\n",
    "        self.process_btn.on_click(self._process_images)\n",
    "        self.match_btn.on_click(self._match_fingerprints)\n",
    "\n",
    "        # Display all widgets\n",
    "        with self.output_widget:\n",
    "            print(\"Fingerprint Matcher initialized\")\n",
    "            display(self.ref_upload)\n",
    "            display(self.samp_upload)\n",
    "            display(self.process_btn)\n",
    "            display(self.match_btn)\n",
    "\n",
    "    def _preprocess_image(self, image_path):\n",
    "        with self.output_widget:\n",
    "            print(f\"Processing image\")\n",
    "            try:\n",
    "                # Read image using PIL from bytes\n",
    "                img_bytes = image_path.tobytes()\n",
    "                img = Image.open(io.BytesIO(img_bytes)) # Use standard Python io.BytesIO\n",
    "\n",
    "                # Convert to grayscale if needed\n",
    "                if img.mode != 'L':\n",
    "                    img = img.convert('L')\n",
    "\n",
    "                # Convert to numpy array\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Apply histogram equalization\n",
    "                enhanced_img = equalize_hist(img_array)\n",
    "\n",
    "                return enhanced_img\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "\n",
    "    def _extract_features(self, processed_image):\n",
    "        with self.output_widget:\n",
    "            print(\"Extracting features...\")\n",
    "            try:\n",
    "                # Ridge detection using Sobel filters\n",
    "                sobel_x = filters.sobel_h(processed_image)\n",
    "                sobel_y = filters.sobel_v(processed_image)\n",
    "\n",
    "                # Combine gradients\n",
    "                gradient = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "                # Find local maxima for minutiae points\n",
    "                min_distance = 10\n",
    "                coordinates = peak_local_max(gradient, min_distance=min_distance)\n",
    "\n",
    "                return coordinates\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting features: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "    def _match_features(self, ref_points, samp_points):\n",
    "        with self.output_widget:\n",
    "            print(\"Matching features...\")\n",
    "            try:\n",
    "                print(f\"Type of ref_points: {type(ref_points)}, Shape: {ref_points.shape if isinstance(ref_points, np.ndarray) else 'N/A'}\")\n",
    "                print(f\"Type of samp_points: {type(samp_points)}, Shape: {samp_points.shape if isinstance(samp_points, np.ndarray) else 'N/A'}\")\n",
    "\n",
    "                # Calculate distances between all point pairs\n",
    "                distances = []\n",
    "                for ref_point in ref_points:\n",
    "                    for samp_point in samp_points:\n",
    "                        dist = euclidean(ref_point, samp_point)\n",
    "                        distances.append(dist)\n",
    "\n",
    "                print(f\"Type of distances: {type(distances)}\") # Debug print for distances type\n",
    "                if distances: # Check if distances is not empty before printing\n",
    "                    print(f\"Type of first distance in distances: {type(distances[0]) if distances else 'N/A'}\") # Debug print for type of element in distances\n",
    "                    if isinstance(distances[0], np.ndarray): # If it's an array, print its shape\n",
    "                        print(f\"Shape of first distance in distances: {distances[0].shape}\")\n",
    "\n",
    "\n",
    "                # Threshold for acceptable matches\n",
    "                threshold = 10\n",
    "                matches = sum(d < threshold for d in distances) # Potential error line\n",
    "\n",
    "                # Calculate similarity score\n",
    "                max_possible_matches = min(len(ref_points), len(samp_points))\n",
    "                similarity_score = (matches / max_possible_matches) * 100\n",
    "\n",
    "                return similarity_score\n",
    "            except Exception as e:\n",
    "                print(f\"Error during matching: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "    def _process_images(self, b):\n",
    "        with self.output_widget:\n",
    "            print(\"\\n=== Processing Images ===\")\n",
    "            # Get uploaded files\n",
    "            ref_files = self.ref_upload.value\n",
    "            samp_files = self.samp_upload.value\n",
    "\n",
    "            print(f\"Type of ref_files: {type(ref_files)}\")  # Debug print - Keep for now for verification\n",
    "            print(f\"Value of ref_files: {ref_files}\")    # Debug print - Keep for now for verification\n",
    "            print(f\"Type of samp_files: {type(samp_files)}\") # Debug print - Keep for now for verification\n",
    "            print(f\"Value of samp_files: {samp_files}\")   # Debug print - Keep for now for verification\n",
    "\n",
    "\n",
    "            if not ref_files or not samp_files:\n",
    "                print(\"Error: Please upload both reference and sample images\")\n",
    "                return\n",
    "\n",
    "            # Process reference image\n",
    "            if ref_files:\n",
    "                # Assume ref_files is a tuple of Bunch objects\n",
    "                for ref_file_info in ref_files: # Iterate directly over the tuple\n",
    "                    print(f\"Processing reference file: {ref_file_info}\") # Debug print - print the Bunch object\n",
    "                    self.ref_image = self._preprocess_image(ref_file_info['content']) # Access 'content'\n",
    "                    break  # Since multiple=False, process only the first file in the tuple\n",
    "\n",
    "            # Process sample image\n",
    "            if samp_files:\n",
    "                # Assume samp_files is a tuple of Bunch objects\n",
    "                for samp_file_info in samp_files: # Iterate directly over the tuple\n",
    "                    print(f\"Processing sample file: {samp_file_info}\") # Debug print - print the Bunch object\n",
    "                    self.samp_image = self._preprocess_image(samp_file_info['content']) # Access 'content'\n",
    "                    break  # Since multiple=False, process only the first file in the tuple\n",
    "\n",
    "\n",
    "            if self.ref_image is None or self.samp_image is None:\n",
    "                print(\"Error: Failed to process one or both images\")\n",
    "                return\n",
    "\n",
    "            # Display processed images\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            axes[0].imshow(self.ref_image, cmap='gray')\n",
    "            axes[0].set_title('Reference Image')\n",
    "            axes[1].imshow(self.samp_image, cmap='gray')\n",
    "            plt.show()\n",
    "            print(\"Images processed successfully!\")\n",
    "\n",
    "\n",
    "    def _match_fingerprints(self, b):\n",
    "        with self.output_widget:\n",
    "            print(\"\\n=== Matching Fingerprints ===\")\n",
    "            if self.ref_image is None or self.samp_image is None:\n",
    "                print(\"Error: Please process images first\")\n",
    "                return\n",
    "\n",
    "            # Extract features\n",
    "            ref_features = self._extract_features(self.ref_image)\n",
    "            samp_features = self._extract_features(self.samp_image)\n",
    "\n",
    "            if ref_features is None or samp_features is None:\n",
    "                print(\"Error: Failed to extract features\")\n",
    "                return\n",
    "\n",
    "            # Match features\n",
    "            score = self._match_features(ref_features, samp_features)\n",
    "\n",
    "            if score is not None:\n",
    "                print(f\"\\nMatching Results:\")\n",
    "                print(f\"Similarity Score: {score:.2f}%\")\n",
    "            else:\n",
    "                print(\"Error: Failed to calculate similarity score\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fingerprint_matcher = FingerprintMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4490c3f5-67d0-42b6-bd17-b02dc4e26fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c647f48cd44ae19b2f6075887ceba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from skimage import io as skio, filters # Alias skimage.io to skio\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.spatial.distance import euclidean\n",
    "from skimage.exposure import equalize_hist\n",
    "import io # Explicitly import the standard Python io module\n",
    "\n",
    "\n",
    "class FingerprintMatcher:\n",
    "    def __init__(self):\n",
    "        # Create output widget for all messages\n",
    "        self.output_widget = widgets.Output()\n",
    "        display(self.output_widget)\n",
    "\n",
    "        # Initialize state\n",
    "        self.ref_image = None\n",
    "        self.samp_image = None\n",
    "        self.ref_features = None  # To store features (coordinates, gradient)\n",
    "        self.samp_features = None  # To store features (coordinates, gradient)\n",
    "\n",
    "\n",
    "        # Create upload widgets\n",
    "        self.ref_upload = widgets.FileUpload(\n",
    "            description='Reference Image',\n",
    "            accept='.jpg,.jpeg,.png,.bmp',\n",
    "            multiple=False\n",
    "        )\n",
    "        self.samp_upload = widgets.FileUpload(\n",
    "            description='Sample Image',\n",
    "            accept='.jpg,.jpeg,.png,.bmp',\n",
    "            multiple=False\n",
    "        )\n",
    "\n",
    "        # Create process and match buttons\n",
    "        self.process_btn = widgets.Button(description='Process Images')\n",
    "        self.match_btn = widgets.Button(description='Match Fingerprints')\n",
    "\n",
    "        # Connect button clicks to functions\n",
    "        self.process_btn.on_click(self._process_images)\n",
    "        self.match_btn.on_click(self._match_fingerprints)\n",
    "\n",
    "        # Display all widgets\n",
    "        with self.output_widget:\n",
    "            print(\"Fingerprint Matcher initialized\")\n",
    "            display(self.ref_upload)\n",
    "            display(self.samp_upload)\n",
    "            display(self.process_btn)\n",
    "            display(self.match_btn)\n",
    "\n",
    "    def _preprocess_image(self, image_path):\n",
    "        with self.output_widget:\n",
    "            print(f\"Processing image\")\n",
    "            try:\n",
    "                # Read image using PIL from bytes\n",
    "                img_bytes = image_path.tobytes()\n",
    "                img = Image.open(io.BytesIO(img_bytes)) # Use standard Python io.BytesIO\n",
    "\n",
    "                # Convert to grayscale if needed\n",
    "                if img.mode != 'L':\n",
    "                    img = img.convert('L')\n",
    "\n",
    "                # Convert to numpy array\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Apply histogram equalization\n",
    "                enhanced_img = equalize_hist(img_array)\n",
    "\n",
    "                return enhanced_img\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "\n",
    "    def _extract_features(self, processed_image):\n",
    "        with self.output_widget:\n",
    "            print(\"Extracting features...\")\n",
    "            try:\n",
    "                # Ridge detection using Sobel filters\n",
    "                sobel_x = filters.sobel_h(processed_image)\n",
    "                sobel_y = filters.sobel_v(processed_image)\n",
    "\n",
    "                # Combine gradients (this is our ridge detail image)\n",
    "                gradient = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "                # Find local maxima for minutiae points\n",
    "                min_distance = 10\n",
    "                coordinates = peak_local_max(gradient, min_distance=min_distance)\n",
    "\n",
    "                print(f\"Number of minutiae detected: {len(coordinates)}\") # Print num of minutiae\n",
    "\n",
    "                return coordinates, gradient # Return both coordinates and gradient\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting features: {str(e)}\")\n",
    "                return None, None # Return None for both in case of error\n",
    "\n",
    "    def _match_features(self, ref_points, samp_points):\n",
    "        with self.output_widget:\n",
    "            print(\"Matching features...\")\n",
    "            try:\n",
    "                print(f\"Type of ref_points: {type(ref_points)}, Shape: {ref_points.shape if isinstance(ref_points, np.ndarray) else 'N/A'}\")\n",
    "                print(f\"Type of samp_points: {type(samp_points)}, Shape: {samp_points.shape if isinstance(samp_points, np.ndarray) else 'N/A'}\")\n",
    "\n",
    "                # Calculate distances between all point pairs\n",
    "                distances = []\n",
    "                for ref_point in ref_points:\n",
    "                    for samp_point in samp_points:\n",
    "                        dist = euclidean(ref_point, samp_point)\n",
    "                        distances.append(dist)\n",
    "\n",
    "                print(f\"Type of distances: {type(distances)}\") # Debug print for distances type\n",
    "                if distances: # Check if distances is not empty before printing\n",
    "                    print(f\"Type of first distance in distances: {type(distances[0]) if distances else 'N/A'}\") # Debug print for type of element in distances\n",
    "                    if isinstance(distances[0], np.ndarray): # If it's an array, print its shape\n",
    "                        print(f\"Shape of first distance in distances: {distances[0].shape}\")\n",
    "\n",
    "\n",
    "                # Threshold for acceptable matches\n",
    "                threshold = 10\n",
    "                matches = sum(d < threshold for d in distances) # Potential error line\n",
    "\n",
    "                # Calculate similarity score\n",
    "                max_possible_matches = min(len(ref_points), len(samp_points))\n",
    "                similarity_score = (matches / max_possible_matches) * 100\n",
    "\n",
    "                return similarity_score\n",
    "            except Exception as e:\n",
    "                print(f\"Error during matching: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "    def _process_images(self, b):\n",
    "        with self.output_widget:\n",
    "            print(\"\\n=== Processing Images ===\")\n",
    "            # Get uploaded files\n",
    "            ref_files = self.ref_upload.value\n",
    "            samp_files = self.samp_upload.value\n",
    "\n",
    "            print(f\"Type of ref_files: {type(ref_files)}\")  # Debug print - Keep for now for verification\n",
    "            print(f\"Value of ref_files: {ref_files}\")    # Debug print - Keep for now for verification\n",
    "            print(f\"Type of samp_files: {type(samp_files)}\") # Debug print - Keep for now for verification\n",
    "            print(f\"Value of samp_files: {samp_files}\")   # Debug print - Keep for now for verification\n",
    "\n",
    "\n",
    "            if not ref_files or not samp_files:\n",
    "                print(\"Error: Please upload both reference and sample images\")\n",
    "                return\n",
    "\n",
    "            # Process reference image\n",
    "            if ref_files:\n",
    "                # Assume ref_files is a tuple of Bunch objects\n",
    "                for ref_file_info in ref_files: # Iterate directly over the tuple\n",
    "                    print(f\"Processing reference file: {ref_file_info}\") # Debug print - print the Bunch object\n",
    "                    self.ref_image = self._preprocess_image(ref_file_info['content']) # Access 'content'\n",
    "                    self.ref_features = self._extract_features(self.ref_image) # Extract features and store\n",
    "                    break  # Since multiple=False, process only the first file in the tuple\n",
    "\n",
    "            # Process sample image\n",
    "            if samp_files:\n",
    "                # Assume samp_files is a tuple of Bunch objects\n",
    "                for samp_file_info in samp_files: # Iterate directly over the tuple\n",
    "                    print(f\"Processing sample file: {samp_file_info}\") # Debug print - print the Bunch object\n",
    "                    self.samp_image = self._preprocess_image(samp_file_info['content']) # Access 'content'\n",
    "                    self.samp_features = self._extract_features(self.samp_image) # Extract features and store\n",
    "                    break  # Since multiple=False, process only the first file in the tuple\n",
    "\n",
    "\n",
    "            if self.ref_image is None or self.samp_image is None or self.ref_features is None or self.samp_features is None:\n",
    "                print(\"Error: Failed to process one or both images or extract features\")\n",
    "                return\n",
    "\n",
    "            # Display processed images and ridge details\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 10)) # 2 rows, 2 columns now\n",
    "\n",
    "            axes[0, 0].imshow(self.ref_image, cmap='gray') # Processed ref image\n",
    "            axes[0, 0].set_title('Processed Reference Image')\n",
    "\n",
    "            axes[0, 1].imshow(self.ref_features[1], cmap='gray') # Ridge detail ref image (gradient)\n",
    "            axes[0, 1].set_title('Reference Ridge Detail')\n",
    "\n",
    "            axes[1, 0].imshow(self.samp_image, cmap='gray') # Processed sample image\n",
    "            axes[1, 0].set_title('Processed Sample Image')\n",
    "\n",
    "            axes[1, 1].imshow(self.samp_features[1], cmap='gray') # Ridge detail sample image (gradient)\n",
    "            axes[1, 1].set_title('Sample Ridge Detail')\n",
    "\n",
    "\n",
    "            plt.tight_layout() # Adjust layout to prevent overlapping titles\n",
    "            plt.show()\n",
    "            print(\"Images and ridge details processed successfully!\")\n",
    "\n",
    "\n",
    "    def _match_fingerprints(self, b):\n",
    "        with self.output_widget:\n",
    "            print(\"\\n=== Matching Fingerprints ===\")\n",
    "            if self.ref_image is None or self.samp_image is None or self.ref_features is None or self.samp_features is None:\n",
    "                print(\"Error: Please process images first and ensure features are extracted\")\n",
    "                return\n",
    "\n",
    "            # Extract features (already done in _process_images, using stored features)\n",
    "            ref_coordinates = self.ref_features[0] # Get coordinates from stored features\n",
    "            samp_coordinates = self.samp_features[0] # Get coordinates from stored features\n",
    "\n",
    "\n",
    "            # Match features\n",
    "            score = self._match_features(ref_coordinates, samp_coordinates)\n",
    "\n",
    "            if score is not None:\n",
    "                print(f\"\\nMatching Results:\")\n",
    "                print(f\"Similarity Score: {score:.2f}%\")\n",
    "\n",
    "                # --- Visualization of Minutiae ---\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(12, 6)) # 1 row, 2 cols for minutiae viz\n",
    "\n",
    "                axes[0].imshow(self.ref_image, cmap='gray')\n",
    "                axes[0].set_title('Reference Image with Minutiae')\n",
    "                axes[0].plot(ref_coordinates[:, 1], ref_coordinates[:, 0], 'ro', markersize=3) # Plot red dots, careful with x, y coordinate order\n",
    "\n",
    "\n",
    "                axes[1].imshow(self.samp_image, cmap='gray')\n",
    "                axes[1].set_title('Sample Image with Minutiae')\n",
    "                axes[1].plot(samp_coordinates[:, 1], samp_coordinates[:, 0], 'ro', markersize=3) # Plot red dots, careful with x, y coordinate order\n",
    "\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                print(\"Minutiae visualized!\")\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(\"Error: Failed to calculate similarity score\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fingerprint_matcher = FingerprintMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9afe7-bd83-437f-baab-8be79f7b2e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
